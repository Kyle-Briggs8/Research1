{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2cb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ceaf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41762, 15)\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   37           Private  284582    Masters             14   \n",
      "4   52  Self-emp-not-inc  209642    HS-grad              9   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
      "4  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              45  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "# Combine features and target into one DataFrame\n",
    "df = X.copy()\n",
    "df['income'] = y['income']\n",
    "\n",
    "# Filter to White individuals and reset the index\n",
    "df_white = df[df['race'].astype(str).str.strip().eq('White')].reset_index(drop=True)\n",
    "\n",
    "# Quick check\n",
    "print(df_white.shape)\n",
    "print(df_white.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1b677d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: income_binary, dtype: float64\n",
      "income_binary\n",
      "0.0    31155\n",
      "1.0    10607\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education-num      marital-status  \\\n",
       "0   39         State-gov  Bachelors             13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors             13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad              9            Divorced   \n",
       "3   37           Private    Masters             14  Married-civ-spouse   \n",
       "4   52  Self-emp-not-inc    HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship     sex  capital-gain  capital-loss  \\\n",
       "0       Adm-clerical  Not-in-family    Male          2174             0   \n",
       "1    Exec-managerial        Husband    Male             0             0   \n",
       "2  Handlers-cleaners  Not-in-family    Male             0             0   \n",
       "3    Exec-managerial           Wife  Female             0             0   \n",
       "4    Exec-managerial        Husband    Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  income_binary  \n",
       "0              40  United-States            0.0  \n",
       "1              13  United-States            0.0  \n",
       "2              40  United-States            0.0  \n",
       "3              40  United-States            0.0  \n",
       "4              45  United-States            1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_white.head()\n",
    "# m_gt = df_white['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "# m_le = df_white['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "\n",
    "df_white['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_white['income_binary'].head())\n",
    "print(df_white['income_binary'].value_counts(dropna=False))\n",
    "df_white.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e6cfb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    1.0\n",
       "Name: income_binary, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_white = df_white.iloc[:, :12]\n",
    "X_white.head()\n",
    "y_white = df_white['income_binary']\n",
    "y_white.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7959c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(X_white, y_white, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5851247e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Private'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_10556\\1214318733.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.ensemble \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m rf_white = RandomForestClassifier()\n\u001b[32m      4\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m rf_white.fit(X_white_train, y_white_train)\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2164\u001b[39m             )\n\u001b[32m   2165\u001b[39m         values = self._values\n\u001b[32m   2166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2167\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2171\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Private'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_white = RandomForestClassifier()\n",
    "\n",
    "rf_white.fit(X_white_train, y_white_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9521025",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_white_pred = rf_white.predict(X_white_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_white.score(X_white_test, y_white_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd1cb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.878     0.934     0.905      6929\n",
      "           1      0.536     0.369     0.437      1424\n",
      "\n",
      "    accuracy                          0.838      8353\n",
      "   macro avg      0.707     0.652     0.671      8353\n",
      "weighted avg      0.820     0.838     0.826      8353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Prepare data\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# df_white already exists with all features + 'income'\n",
    "df_model = df_white.copy()\n",
    "df_model['income_bin'] = (df_model['income'].astype(str).str.strip().eq('>50K')).astype(int)\n",
    "X = df_model.drop(columns=['income', 'income_bin'])\n",
    "y = df_model['income_bin']\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 2) Preprocess + model pipeline\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_cols),\n",
    "        ('cat', categorical_pipeline, categorical_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[('prep', preprocess), ('rf', model)])\n",
    "\n",
    "# 3) Train/test split and fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4) Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc:.3f}')\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f515e5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing tree depth requirements for different races...\n",
      "\n",
      "=== Testing White (n=41762) ===\n",
      "Class distribution: {0: 34645, 1: 7117}\n",
      "Depth  1: Accuracy = 0.830\n",
      "Depth  2: Accuracy = 0.830\n",
      "Depth  3: Accuracy = 0.830\n",
      "Depth  4: Accuracy = 0.833\n",
      "Depth  5: Accuracy = 0.837\n",
      "Depth  6: Accuracy = 0.836\n",
      "Depth  7: Accuracy = 0.839\n",
      "Depth  8: Accuracy = 0.841\n",
      "Depth  9: Accuracy = 0.843\n",
      "Depth 10: Accuracy = 0.844\n",
      "Depth 11: Accuracy = 0.844\n",
      "Depth 12: Accuracy = 0.845\n",
      "Depth 13: Accuracy = 0.847\n",
      "Depth 14: Accuracy = 0.845\n",
      "Depth 15: Accuracy = 0.847\n",
      "Depth 16: Accuracy = 0.845\n",
      "Depth 17: Accuracy = 0.846\n",
      "Depth 18: Accuracy = 0.846\n",
      "Depth 19: Accuracy = 0.844\n",
      "Depth 20: Accuracy = 0.844\n"
     ]
    }
   ],
   "source": [
    "# Function to test tree depth vs accuracy for each race\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def test_tree_depth_for_race(df, race_name, max_depth_range=range(1, 21)):\n",
    "    \"\"\"\n",
    "    Test different tree depths to find minimum depth for 90% accuracy\n",
    "    \"\"\"\n",
    "    # Filter to specific race\n",
    "    df_race = df[df['race'].astype(str).str.strip().eq(race_name)].reset_index(drop=True)\n",
    "    \n",
    "    if len(df_race) < 100:  # Skip if too few samples\n",
    "        print(f\"Not enough samples for {race_name}: {len(df_race)}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n=== Testing {race_name} (n={len(df_race)}) ===\")\n",
    "    \n",
    "    # Prepare data\n",
    "    df_model = df_race.copy()\n",
    "    df_model['income_bin'] = (df_model['income'].astype(str).str.strip().eq('>50K')).astype(int)\n",
    "    X = df_model.drop(columns=['income', 'income_bin'])\n",
    "    y = df_model['income_bin']\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
    "    \n",
    "    # Identify column types\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Preprocessing pipeline\n",
    "    numeric_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "    ])\n",
    "    \n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "    ])\n",
    "    \n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_pipeline, numeric_cols),\n",
    "            ('cat', categorical_pipeline, categorical_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    # Test different depths\n",
    "    results = []\n",
    "    \n",
    "    for depth in max_depth_range:\n",
    "        # Create model with specific depth\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,  # Fewer trees for faster testing\n",
    "            max_depth=depth,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        clf = Pipeline(steps=[('prep', preprocess), ('rf', model)])\n",
    "        \n",
    "        # Train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.20, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Fit and predict\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({'depth': depth, 'accuracy': acc})\n",
    "        \n",
    "        print(f\"Depth {depth:2d}: Accuracy = {acc:.3f}\")\n",
    "        \n",
    "        # Stop if we reach 90% accuracy\n",
    "        if acc >= 0.90:\n",
    "            print(f\"*** 90% accuracy reached at depth {depth} for {race_name} ***\")\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test for White individuals first\n",
    "print(\"Testing tree depth requirements for different races...\")\n",
    "white_results = test_tree_depth_for_race(df, 'White')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336acd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available races in dataset:\n",
      "race\n",
      "White                 41762\n",
      "Black                  4685\n",
      "Asian-Pac-Islander     1519\n",
      "Amer-Indian-Eskimo      470\n",
      "Other                   406\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Testing White (n=41762) ===\n",
      "Class distribution: {0: 34645, 1: 7117}\n",
      "Depth  1: Accuracy = 0.830\n",
      "Depth  2: Accuracy = 0.830\n",
      "Depth  3: Accuracy = 0.830\n",
      "Depth  4: Accuracy = 0.833\n",
      "Depth  5: Accuracy = 0.837\n",
      "Depth  6: Accuracy = 0.836\n",
      "Depth  7: Accuracy = 0.839\n",
      "Depth  8: Accuracy = 0.841\n",
      "Depth  9: Accuracy = 0.843\n",
      "Depth 10: Accuracy = 0.844\n",
      "Depth 11: Accuracy = 0.844\n",
      "Depth 12: Accuracy = 0.845\n",
      "Depth 13: Accuracy = 0.847\n",
      "Depth 14: Accuracy = 0.845\n",
      "Depth 15: Accuracy = 0.847\n",
      "Depth 16: Accuracy = 0.845\n",
      "Depth 17: Accuracy = 0.846\n",
      "Depth 18: Accuracy = 0.846\n",
      "Depth 19: Accuracy = 0.844\n",
      "Depth 20: Accuracy = 0.844\n",
      "\n",
      "=== Testing Black (n=4685) ===\n",
      "Class distribution: {0: 4298, 1: 387}\n",
      "Depth  1: Accuracy = 0.918\n",
      "*** 90% accuracy reached at depth 1 for Black ***\n",
      "\n",
      "=== Testing Asian-Pac-Islander (n=1519) ===\n",
      "Class distribution: {0: 1243, 1: 276}\n",
      "Depth  1: Accuracy = 0.819\n",
      "Depth  2: Accuracy = 0.819\n",
      "Depth  3: Accuracy = 0.822\n",
      "Depth  4: Accuracy = 0.816\n",
      "Depth  5: Accuracy = 0.809\n",
      "Depth  6: Accuracy = 0.812\n",
      "Depth  7: Accuracy = 0.809\n",
      "Depth  8: Accuracy = 0.809\n",
      "Depth  9: Accuracy = 0.819\n",
      "Depth 10: Accuracy = 0.812\n",
      "Depth 11: Accuracy = 0.816\n",
      "Depth 12: Accuracy = 0.812\n",
      "Depth 13: Accuracy = 0.812\n",
      "Depth 14: Accuracy = 0.819\n",
      "Depth 15: Accuracy = 0.816\n",
      "Depth 16: Accuracy = 0.822\n",
      "Depth 17: Accuracy = 0.816\n",
      "Depth 18: Accuracy = 0.829\n",
      "Depth 19: Accuracy = 0.826\n",
      "Depth 20: Accuracy = 0.832\n",
      "\n",
      "=== Testing Amer-Indian-Eskimo (n=470) ===\n",
      "Class distribution: {0: 434, 1: 36}\n",
      "Depth  1: Accuracy = 0.926\n",
      "*** 90% accuracy reached at depth 1 for Amer-Indian-Eskimo ***\n",
      "\n",
      "=== Testing Other (n=406) ===\n",
      "Class distribution: {0: 381, 1: 25}\n",
      "Depth  1: Accuracy = 0.939\n",
      "*** 90% accuracy reached at depth 1 for Other ***\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Minimum tree depth for 90% accuracy\n",
      "============================================================\n",
      "White               : Max accuracy 0.847 (never reached 90%)\n",
      "Black               : Depth  1 needed for 90% accuracy\n",
      "Asian-Pac-Islander  : Max accuracy 0.832 (never reached 90%)\n",
      "Amer-Indian-Eskimo  : Depth  1 needed for 90% accuracy\n",
      "Other               : Depth  1 needed for 90% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Test all races and compare results\n",
    "print(\"Checking available races in dataset:\")\n",
    "print(df['race'].value_counts())\n",
    "\n",
    "# Test each race\n",
    "races_to_test = ['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other']\n",
    "all_results = {}\n",
    "\n",
    "for race in races_to_test:\n",
    "    results = test_tree_depth_for_race(df, race)\n",
    "    if results is not None:\n",
    "        all_results[race] = results\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: Minimum tree depth for 90% accuracy\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for race, results_df in all_results.items():\n",
    "    if len(results_df) > 0:\n",
    "        max_acc = results_df['accuracy'].max()\n",
    "        depth_at_90 = results_df[results_df['accuracy'] >= 0.90]['depth'].min()\n",
    "        \n",
    "        if pd.isna(depth_at_90):\n",
    "            print(f\"{race:20s}: Max accuracy {max_acc:.3f} (never reached 90%)\")\n",
    "        else:\n",
    "            print(f\"{race:20s}: Depth {depth_at_90:2d} needed for 90% accuracy\")\n",
    "    else:\n",
    "        print(f\"{race:20s}: No results available\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
