{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7799fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 2, 'name': 'Adult', 'repository_url': 'https://archive.ics.uci.edu/dataset/2/adult', 'data_url': 'https://archive.ics.uci.edu/static/public/2/data.csv', 'abstract': 'Predict whether annual income of an individual exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. ', 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 48842, 'num_features': 14, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Income', 'Education Level', 'Other', 'Race', 'Sex'], 'target_col': ['income'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1996, 'last_updated': 'Tue Sep 24 2024', 'dataset_doi': '10.24432/C5XW20', 'creators': ['Barry Becker', 'Ronny Kohavi'], 'intro_paper': None, 'additional_info': {'summary': \"Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\\n\\nPrediction task is to determine whether a person's income is over $50,000 a year.\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Listing of attributes:\\r\\n\\r\\n>50K, <=50K.\\r\\n\\r\\nage: continuous.\\r\\nworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\\r\\nfnlwgt: continuous.\\r\\neducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\\r\\neducation-num: continuous.\\r\\nmarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\\r\\noccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\\r\\nrelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\\r\\nrace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\\r\\nsex: Female, Male.\\r\\ncapital-gain: continuous.\\r\\ncapital-loss: continuous.\\r\\nhours-per-week: continuous.\\r\\nnative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.', 'citation': None}}\n",
      "              name     role         type      demographic  \\\n",
      "0              age  Feature      Integer              Age   \n",
      "1        workclass  Feature  Categorical           Income   \n",
      "2           fnlwgt  Feature      Integer             None   \n",
      "3        education  Feature  Categorical  Education Level   \n",
      "4    education-num  Feature      Integer  Education Level   \n",
      "5   marital-status  Feature  Categorical            Other   \n",
      "6       occupation  Feature  Categorical            Other   \n",
      "7     relationship  Feature  Categorical            Other   \n",
      "8             race  Feature  Categorical             Race   \n",
      "9              sex  Feature       Binary              Sex   \n",
      "10    capital-gain  Feature      Integer             None   \n",
      "11    capital-loss  Feature      Integer             None   \n",
      "12  hours-per-week  Feature      Integer             None   \n",
      "13  native-country  Feature  Categorical            Other   \n",
      "14          income   Target       Binary           Income   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                 N/A  None             no  \n",
      "1   Private, Self-emp-not-inc, Self-emp-inc, Feder...  None            yes  \n",
      "2                                                None  None             no  \n",
      "3    Bachelors, Some-college, 11th, HS-grad, Prof-...  None             no  \n",
      "4                                                None  None             no  \n",
      "5   Married-civ-spouse, Divorced, Never-married, S...  None             no  \n",
      "6   Tech-support, Craft-repair, Other-service, Sal...  None            yes  \n",
      "7   Wife, Own-child, Husband, Not-in-family, Other...  None             no  \n",
      "8   White, Asian-Pac-Islander, Amer-Indian-Eskimo,...  None             no  \n",
      "9                                       Female, Male.  None             no  \n",
      "10                                               None  None             no  \n",
      "11                                               None  None             no  \n",
      "12                                               None  None             no  \n",
      "13  United-States, Cambodia, England, Puerto-Rico,...  None            yes  \n",
      "14                                       >50K, <=50K.  None             no  \n",
      "(41762, 15)\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   37           Private  284582    Masters             14   \n",
      "4   52  Self-emp-not-inc  209642    HS-grad              9   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
      "4  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              45  United-States   >50K  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) \n",
    "\n",
    "\n",
    "# Combine features and target into one DataFrame\n",
    "df = X.copy()\n",
    "df['income'] = y['income']\n",
    "\n",
    "# Filter for each of given races\n",
    "df_white = df[df['race'].astype(str).str.strip().eq('White')].reset_index(drop=True)\n",
    "df_black = df[df['race'].astype(str).str.strip().eq('Black')].reset_index(drop=True)\n",
    "df_asian = df[df['race'].astype(str).str.strip().eq('Asian-Pac-Islander')].reset_index(drop=True)\n",
    "df_native = df[df['race'].astype(str).str.strip().eq('Amer-Indian-Eskimo')].reset_index(drop=True)\n",
    "df_other = df[df['race'].astype(str).str.strip().eq('Other')].reset_index(drop=True)\n",
    "# Quick check\n",
    "print(df_white.shape)\n",
    "print(df_white.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a688ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: income_binary, dtype: float64\n",
      "income_binary\n",
      "0.0    31155\n",
      "1.0    10607\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# changes all of the income into 1 and 0 based on if over 50k or if less than\n",
    "m_gt = df_white['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "m_le = df_white['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "df_white['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_white['income_binary'].head())\n",
    "print(df_white['income_binary'].value_counts(dropna=False))\n",
    "df_white.head()\n",
    "df_white.drop(columns=['income'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a77322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shapes: (33409, 97) (8353, 97)\n",
      "First 10 features: ['num__age' 'num__education-num' 'num__capital-gain' 'num__capital-loss'\n",
      " 'num__hours-per-week' 'cat__workclass_Federal-gov'\n",
      " 'cat__workclass_Local-gov' 'cat__workclass_Never-worked'\n",
      " 'cat__workclass_Private' 'cat__workclass_Self-emp-inc'\n",
      " 'cat__workclass_Self-emp-not-inc' 'cat__workclass_State-gov'\n",
      " 'cat__workclass_Without-pay' 'cat__education_10th' 'cat__education_11th'\n",
      " 'cat__education_12th' 'cat__education_1st-4th' 'cat__education_5th-6th'\n",
      " 'cat__education_7th-8th' 'cat__education_9th' 'cat__education_Assoc-acdm'\n",
      " 'cat__education_Assoc-voc' 'cat__education_Bachelors'\n",
      " 'cat__education_Doctorate' 'cat__education_HS-grad'\n",
      " 'cat__education_Masters' 'cat__education_Preschool'\n",
      " 'cat__education_Prof-school' 'cat__education_Some-college'\n",
      " 'cat__marital-status_Divorced' 'cat__marital-status_Married-AF-spouse'\n",
      " 'cat__marital-status_Married-civ-spouse'\n",
      " 'cat__marital-status_Married-spouse-absent'\n",
      " 'cat__marital-status_Never-married' 'cat__marital-status_Separated'\n",
      " 'cat__marital-status_Widowed' 'cat__occupation_Adm-clerical'\n",
      " 'cat__occupation_Armed-Forces' 'cat__occupation_Craft-repair'\n",
      " 'cat__occupation_Exec-managerial' 'cat__occupation_Farming-fishing'\n",
      " 'cat__occupation_Handlers-cleaners' 'cat__occupation_Machine-op-inspct'\n",
      " 'cat__occupation_Other-service' 'cat__occupation_Priv-house-serv'\n",
      " 'cat__occupation_Prof-specialty' 'cat__occupation_Protective-serv'\n",
      " 'cat__occupation_Sales' 'cat__occupation_Tech-support'\n",
      " 'cat__occupation_Transport-moving']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- start from your dataframe: df_white ---\n",
    "# Ensure that is either 1 or 0 \n",
    "if df_white['income_binary'].dtype == 'O':\n",
    "    y_white = (df_white['income_binary'].astype(str)\n",
    "               .str.strip()\n",
    "               .replace({'>50K': 1, '<=50K': 0, '> 50K': 1, '<= 50K': 0})\n",
    "               .astype(int))\n",
    "else:\n",
    "    y_white = df_white['income_binary'].astype(int)\n",
    "\n",
    "# drops unwanted columns from X df\n",
    "X_white = df_white.drop(columns=['income_binary', 'fnlwgt', 'race'], errors='ignore').copy()\n",
    "\n",
    "# Identify numeric vs categorical\n",
    "num_cols_white = X_white.select_dtypes(include=['number', 'bool']).columns.tolist()\n",
    "cat_cols_white = [c for c in X_white.columns if c not in num_cols_white]\n",
    "\n",
    "# Clean categorical text and mark nans \n",
    "for c in cat_cols_white:\n",
    "    X_white[c] = X_white[c].astype(str).str.strip().replace({'?': np.nan})\n",
    "    X_white[c] = X_white[c].replace(r'(?i)^nan$', np.nan, regex=True)\n",
    "\n",
    "\n",
    "# split up and ensure proportion \n",
    "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(\n",
    "    X_white, y_white, test_size=0.2, random_state=0, stratify=y_white\n",
    ")\n",
    "\n",
    "# Preprocessor: simple impute fills missing values with the most frequent category in that column + OHE\n",
    "preprocess_white = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), num_cols_white),\n",
    "        ('cat', Pipeline([\n",
    "            ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), cat_cols_white),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit on train; transform both splits (optional if you’ll use the pipeline below)\n",
    "preprocess_white.fit(X_white_train)\n",
    "X_white_train_enc = preprocess_white.transform(X_white_train)\n",
    "X_white_test_enc  = preprocess_white.transform(X_white_test)\n",
    "print(\"Encoded shapes:\", X_white_train_enc.shape, X_white_test_enc.shape)\n",
    "feature_names = preprocess_white.get_feature_names_out()\n",
    "print(\"First 10 features:\", feature_names[:50])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6ce101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8311983718424518\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.882     0.893     0.888      6231\n",
      "           1      0.674     0.650     0.662      2122\n",
      "\n",
      "    accuracy                          0.831      8353\n",
      "   macro avg      0.778     0.772     0.775      8353\n",
      "weighted avg      0.829     0.831     0.830      8353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Pipeline: reuse your fitted preprocessor object 1000 decision trees \n",
    "rf_white = Pipeline([\n",
    "    ('prep', preprocess_white),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=1000,\n",
    "        random_state=0,\n",
    "        n_jobs=-1,\n",
    "        max_depth=None,\n",
    "        class_weight='balanced_subsample'  # makes balanced\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "rf_white.fit(X_white_train, y_white_train)\n",
    "\n",
    "# Evaluate\n",
    "y_white_pred = rf_white.predict(X_white_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_white_test, y_white_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_white_test, y_white_pred, digits=3))\n",
    "\n",
    "# Top features\n",
    "# importances = rf_white.named_steps['rf'].feature_importances_\n",
    "# feat_names = rf_white.named_steps['prep'].get_feature_names_out()\n",
    "# order = np.argsort(importances)[::-1][:15]\n",
    "# print(\"\\nTop 15 features:\")\n",
    "# for i in order:\n",
    "#     print(f\"{feat_names[i]:40s} {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2d5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def evaluate_rf_depths(\n",
    "    df,\n",
    "    target_col='income_binary',\n",
    "    drop_cols=('fnlwgt', 'race'),\n",
    "    depths=range(1, 21),           # try depths 1..20 (change as you like)\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    "    rf_kwargs=None                 # extra RF kwargs if you want to tweak\n",
    "):\n",
    "    # pair column to 1 or 0 based on income values \n",
    "    y_raw = df[target_col]\n",
    "    if y_raw.dtype == 'O':\n",
    "        s = (y_raw.astype(str).str.strip().str.upper()\n",
    "                       .str.replace(r'\\.$', '', regex=True)\n",
    "                       .str.replace(r'\\s+', '', regex=True))\n",
    "        y = s.map({'>50K': 1, '<=50K': 0}).astype(int)\n",
    "    else:\n",
    "        y = y_raw.astype(int)\n",
    "\n",
    "    # drop cols \n",
    "    X = df.drop(columns=[target_col, *drop_cols], errors='ignore').copy()\n",
    "\n",
    "    # split numeric and categorical columns \n",
    "    num_cols = X.select_dtypes(include=['number', 'bool']).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    #  cleaning for categoricals: trim; convert '?' and literal 'nan' to NaN\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype(str).str.strip()\n",
    "        X[c] = X[c].replace({'?': np.nan})\n",
    "        X[c] = X[c].replace(r'(?i)^nan$', np.nan, regex=True)\n",
    "\n",
    "    # Single split reused for every model\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessor: impute numerics + categoricals; OHE categoricals\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', SimpleImputer(strategy='median'), num_cols),\n",
    "            ('cat', Pipeline([\n",
    "                ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # Base RF settings 1000 decision trees\n",
    "    base_rf = dict(\n",
    "        n_estimators=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "        class_weight='balanced_subsample'\n",
    "    )\n",
    "    if rf_kwargs:\n",
    "        base_rf.update(rf_kwargs)\n",
    "\n",
    "    #loop over depths \n",
    "    rows = []\n",
    "    for d in depths:\n",
    "        # builds a pipeline preprocessing RandomForest(max_depth=d).\n",
    "        clf = Pipeline([\n",
    "            ('prep', preproc),\n",
    "            ('rf', RandomForestClassifier(max_depth=d, **base_rf))\n",
    "        ])\n",
    "        # fits the model on the training set \n",
    "        clf.fit(X_tr, y_tr)\n",
    "\n",
    "        # model precision and accuracy scoring \n",
    "        y_pred = clf.predict(X_te)\n",
    "        acc = accuracy_score(y_te, y_pred)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_te, y_pred, average=None, labels=[0,1], zero_division=0\n",
    "        )\n",
    "        # ROC-AUC (needs probabilities; if a class is missing in train it may error)\n",
    "        try:\n",
    "            y_proba = clf.predict_proba(X_te)[:, 1]\n",
    "            auc = roc_auc_score(y_te, y_proba)\n",
    "        except Exception:\n",
    "            auc = np.nan\n",
    "\n",
    "        rows.append({\n",
    "            'max_depth': d,\n",
    "            'accuracy': acc,\n",
    "            'precision_0': prec[0], 'recall_0': rec[0], 'f1_0': f1[0],\n",
    "            'precision_1': prec[1], 'recall_1': rec[1], 'f1_1': f1[1],\n",
    "            'roc_auc': auc\n",
    "        })\n",
    "\n",
    "    results = pd.DataFrame(rows).sort_values('max_depth').reset_index(drop=True)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8a2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: income_binary, dtype: float64\n",
      "income_binary\n",
      "0.0    31155\n",
      "1.0    10607\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_white.head()\n",
    "\n",
    "m_gt = df_white['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "m_le = df_white['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "df_white['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_white['income_binary'].head())\n",
    "print(df_white['income_binary'].value_counts(dropna=False))\n",
    "df_white.head()\n",
    "df_white.drop(columns=['income'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee9f1d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.720460</td>\n",
       "      <td>0.920916</td>\n",
       "      <td>0.683999</td>\n",
       "      <td>0.784971</td>\n",
       "      <td>0.471409</td>\n",
       "      <td>0.827521</td>\n",
       "      <td>0.600650</td>\n",
       "      <td>0.861696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.723093</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>0.682074</td>\n",
       "      <td>0.786091</td>\n",
       "      <td>0.474675</td>\n",
       "      <td>0.843544</td>\n",
       "      <td>0.607500</td>\n",
       "      <td>0.868124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.731713</td>\n",
       "      <td>0.932943</td>\n",
       "      <td>0.689937</td>\n",
       "      <td>0.793247</td>\n",
       "      <td>0.484112</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>0.618033</td>\n",
       "      <td>0.876324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.736741</td>\n",
       "      <td>0.942299</td>\n",
       "      <td>0.689295</td>\n",
       "      <td>0.796181</td>\n",
       "      <td>0.489855</td>\n",
       "      <td>0.876060</td>\n",
       "      <td>0.628359</td>\n",
       "      <td>0.882444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.741410</td>\n",
       "      <td>0.945113</td>\n",
       "      <td>0.693629</td>\n",
       "      <td>0.800074</td>\n",
       "      <td>0.494974</td>\n",
       "      <td>0.881715</td>\n",
       "      <td>0.634022</td>\n",
       "      <td>0.888457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.746917</td>\n",
       "      <td>0.947014</td>\n",
       "      <td>0.699888</td>\n",
       "      <td>0.804910</td>\n",
       "      <td>0.501067</td>\n",
       "      <td>0.885014</td>\n",
       "      <td>0.639864</td>\n",
       "      <td>0.893546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.759607</td>\n",
       "      <td>0.949925</td>\n",
       "      <td>0.715455</td>\n",
       "      <td>0.816185</td>\n",
       "      <td>0.515574</td>\n",
       "      <td>0.889255</td>\n",
       "      <td>0.652715</td>\n",
       "      <td>0.898207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.774452</td>\n",
       "      <td>0.951402</td>\n",
       "      <td>0.735195</td>\n",
       "      <td>0.829441</td>\n",
       "      <td>0.533635</td>\n",
       "      <td>0.889727</td>\n",
       "      <td>0.667138</td>\n",
       "      <td>0.901306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.781994</td>\n",
       "      <td>0.950368</td>\n",
       "      <td>0.746750</td>\n",
       "      <td>0.836344</td>\n",
       "      <td>0.543535</td>\n",
       "      <td>0.885485</td>\n",
       "      <td>0.673597</td>\n",
       "      <td>0.904241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.788340</td>\n",
       "      <td>0.949990</td>\n",
       "      <td>0.756058</td>\n",
       "      <td>0.842002</td>\n",
       "      <td>0.552151</td>\n",
       "      <td>0.883129</td>\n",
       "      <td>0.679478</td>\n",
       "      <td>0.906134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.790854</td>\n",
       "      <td>0.949479</td>\n",
       "      <td>0.760071</td>\n",
       "      <td>0.844282</td>\n",
       "      <td>0.555721</td>\n",
       "      <td>0.881244</td>\n",
       "      <td>0.681611</td>\n",
       "      <td>0.907480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.796361</td>\n",
       "      <td>0.947275</td>\n",
       "      <td>0.769860</td>\n",
       "      <td>0.849402</td>\n",
       "      <td>0.564001</td>\n",
       "      <td>0.874175</td>\n",
       "      <td>0.685640</td>\n",
       "      <td>0.908830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.802346</td>\n",
       "      <td>0.946568</td>\n",
       "      <td>0.779008</td>\n",
       "      <td>0.854653</td>\n",
       "      <td>0.573023</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>0.691229</td>\n",
       "      <td>0.909743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.803304</td>\n",
       "      <td>0.943371</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.855940</td>\n",
       "      <td>0.575338</td>\n",
       "      <td>0.861923</td>\n",
       "      <td>0.690058</td>\n",
       "      <td>0.910508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.809170</td>\n",
       "      <td>0.942884</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.860980</td>\n",
       "      <td>0.584670</td>\n",
       "      <td>0.859095</td>\n",
       "      <td>0.695802</td>\n",
       "      <td>0.910998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.812283</td>\n",
       "      <td>0.941321</td>\n",
       "      <td>0.798106</td>\n",
       "      <td>0.863818</td>\n",
       "      <td>0.590228</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>0.697997</td>\n",
       "      <td>0.911317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.814558</td>\n",
       "      <td>0.938554</td>\n",
       "      <td>0.804044</td>\n",
       "      <td>0.866108</td>\n",
       "      <td>0.595025</td>\n",
       "      <td>0.845429</td>\n",
       "      <td>0.698462</td>\n",
       "      <td>0.911202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.818867</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.811266</td>\n",
       "      <td>0.869827</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.841188</td>\n",
       "      <td>0.702341</td>\n",
       "      <td>0.911224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.822459</td>\n",
       "      <td>0.933370</td>\n",
       "      <td>0.820575</td>\n",
       "      <td>0.873345</td>\n",
       "      <td>0.611130</td>\n",
       "      <td>0.827992</td>\n",
       "      <td>0.703222</td>\n",
       "      <td>0.911052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.824135</td>\n",
       "      <td>0.931810</td>\n",
       "      <td>0.824587</td>\n",
       "      <td>0.874926</td>\n",
       "      <td>0.615005</td>\n",
       "      <td>0.822809</td>\n",
       "      <td>0.703890</td>\n",
       "      <td>0.910608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  accuracy  precision_0  recall_0      f1_0  precision_1  \\\n",
       "0           1  0.720460     0.920916  0.683999  0.784971     0.471409   \n",
       "1           2  0.723093     0.927543  0.682074  0.786091     0.474675   \n",
       "2           3  0.731713     0.932943  0.689937  0.793247     0.484112   \n",
       "3           4  0.736741     0.942299  0.689295  0.796181     0.489855   \n",
       "4           5  0.741410     0.945113  0.693629  0.800074     0.494974   \n",
       "5           6  0.746917     0.947014  0.699888  0.804910     0.501067   \n",
       "6           7  0.759607     0.949925  0.715455  0.816185     0.515574   \n",
       "7           8  0.774452     0.951402  0.735195  0.829441     0.533635   \n",
       "8           9  0.781994     0.950368  0.746750  0.836344     0.543535   \n",
       "9          10  0.788340     0.949990  0.756058  0.842002     0.552151   \n",
       "10         11  0.790854     0.949479  0.760071  0.844282     0.555721   \n",
       "11         12  0.796361     0.947275  0.769860  0.849402     0.564001   \n",
       "12         13  0.802346     0.946568  0.779008  0.854653     0.573023   \n",
       "13         14  0.803304     0.943371  0.783341  0.855940     0.575338   \n",
       "14         15  0.809170     0.942884  0.792168  0.860980     0.584670   \n",
       "15         16  0.812283     0.941321  0.798106  0.863818     0.590228   \n",
       "16         17  0.814558     0.938554  0.804044  0.866108     0.595025   \n",
       "17         18  0.818867     0.937500  0.811266  0.869827     0.602837   \n",
       "18         19  0.822459     0.933370  0.820575  0.873345     0.611130   \n",
       "19         20  0.824135     0.931810  0.824587  0.874926     0.615005   \n",
       "\n",
       "    recall_1      f1_1   roc_auc  \n",
       "0   0.827521  0.600650  0.861696  \n",
       "1   0.843544  0.607500  0.868124  \n",
       "2   0.854383  0.618033  0.876324  \n",
       "3   0.876060  0.628359  0.882444  \n",
       "4   0.881715  0.634022  0.888457  \n",
       "5   0.885014  0.639864  0.893546  \n",
       "6   0.889255  0.652715  0.898207  \n",
       "7   0.889727  0.667138  0.901306  \n",
       "8   0.885485  0.673597  0.904241  \n",
       "9   0.883129  0.679478  0.906134  \n",
       "10  0.881244  0.681611  0.907480  \n",
       "11  0.874175  0.685640  0.908830  \n",
       "12  0.870877  0.691229  0.909743  \n",
       "13  0.861923  0.690058  0.910508  \n",
       "14  0.859095  0.695802  0.910998  \n",
       "15  0.853911  0.697997  0.911317  \n",
       "16  0.845429  0.698462  0.911202  \n",
       "17  0.841188  0.702341  0.911224  \n",
       "18  0.827992  0.703222  0.911052  \n",
       "19  0.822809  0.703890  0.910608  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rf_depths(df_white)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e912db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: income_binary, dtype: float64\n",
      "income_binary\n",
      "0.0    4119\n",
      "1.0     566\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_black.head()\n",
    "\n",
    "m_gt = df_black['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "m_le = df_black['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "df_black['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_black['income_binary'].head())\n",
    "print(df_black['income_binary'].value_counts(dropna=False))\n",
    "df_black.head()\n",
    "df_black.drop(columns=['income'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e1546da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.818570</td>\n",
       "      <td>0.969828</td>\n",
       "      <td>0.819175</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.519774</td>\n",
       "      <td>0.905646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.822839</td>\n",
       "      <td>0.972701</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.890789</td>\n",
       "      <td>0.390041</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.531073</td>\n",
       "      <td>0.915118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.826041</td>\n",
       "      <td>0.975540</td>\n",
       "      <td>0.822816</td>\n",
       "      <td>0.892693</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>0.849558</td>\n",
       "      <td>0.540845</td>\n",
       "      <td>0.919404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.828175</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.822816</td>\n",
       "      <td>0.893869</td>\n",
       "      <td>0.401639</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.923485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.830309</td>\n",
       "      <td>0.982583</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.894911</td>\n",
       "      <td>0.407258</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.559557</td>\n",
       "      <td>0.926937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.833511</td>\n",
       "      <td>0.984058</td>\n",
       "      <td>0.824029</td>\n",
       "      <td>0.896962</td>\n",
       "      <td>0.412955</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.928806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.837780</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.833738</td>\n",
       "      <td>0.900393</td>\n",
       "      <td>0.417021</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.929735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.846318</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.843447</td>\n",
       "      <td>0.906128</td>\n",
       "      <td>0.431718</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>0.576471</td>\n",
       "      <td>0.930702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.851654</td>\n",
       "      <td>0.977685</td>\n",
       "      <td>0.850728</td>\n",
       "      <td>0.909799</td>\n",
       "      <td>0.440909</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.582583</td>\n",
       "      <td>0.931733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.863394</td>\n",
       "      <td>0.974114</td>\n",
       "      <td>0.867718</td>\n",
       "      <td>0.917843</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.931647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.871932</td>\n",
       "      <td>0.971850</td>\n",
       "      <td>0.879854</td>\n",
       "      <td>0.923567</td>\n",
       "      <td>0.481675</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.931872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.876201</td>\n",
       "      <td>0.967018</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.491620</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.931786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.880470</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.898058</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>0.502959</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.931636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.881537</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.904126</td>\n",
       "      <td>0.930668</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.931969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.886873</td>\n",
       "      <td>0.959079</td>\n",
       "      <td>0.910194</td>\n",
       "      <td>0.933998</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.931851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.887940</td>\n",
       "      <td>0.957962</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.934742</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.931421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.889007</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.935644</td>\n",
       "      <td>0.531034</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.933011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.894344</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.938851</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.933043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.898613</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.928398</td>\n",
       "      <td>0.941538</td>\n",
       "      <td>0.566176</td>\n",
       "      <td>0.681416</td>\n",
       "      <td>0.618474</td>\n",
       "      <td>0.933494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.893276</td>\n",
       "      <td>0.946914</td>\n",
       "      <td>0.930825</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.619469</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.932914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  accuracy  precision_0  recall_0      f1_0  precision_1  \\\n",
       "0           1  0.818570     0.969828  0.819175  0.888158     0.381743   \n",
       "1           2  0.822839     0.972701  0.821602  0.890789     0.390041   \n",
       "2           3  0.826041     0.975540  0.822816  0.892693     0.396694   \n",
       "3           4  0.828175     0.978355  0.822816  0.893869     0.401639   \n",
       "4           5  0.830309     0.982583  0.821602  0.894911     0.407258   \n",
       "5           6  0.833511     0.984058  0.824029  0.896962     0.412955   \n",
       "6           7  0.837780     0.978632  0.833738  0.900393     0.417021   \n",
       "7           8  0.846318     0.978873  0.843447  0.906128     0.431718   \n",
       "8           9  0.851654     0.977685  0.850728  0.909799     0.440909   \n",
       "9          10  0.863394     0.974114  0.867718  0.917843     0.463054   \n",
       "10         11  0.871932     0.971850  0.879854  0.923567     0.481675   \n",
       "11         12  0.876201     0.967018  0.889563  0.926675     0.491620   \n",
       "12         13  0.880470     0.963542  0.898058  0.929648     0.502959   \n",
       "13         14  0.881537     0.958816  0.904126  0.930668     0.506250   \n",
       "14         15  0.886873     0.959079  0.910194  0.933998     0.522581   \n",
       "15         16  0.887940     0.957962  0.912621  0.934742     0.526316   \n",
       "16         17  0.889007     0.954545  0.917476  0.935644     0.531034   \n",
       "17         18  0.894344     0.955975  0.922330  0.938851     0.549296   \n",
       "18         19  0.898613     0.955056  0.928398  0.941538     0.566176   \n",
       "19         20  0.893276     0.946914  0.930825  0.938800     0.551181   \n",
       "\n",
       "    recall_1      f1_1   roc_auc  \n",
       "0   0.814159  0.519774  0.905646  \n",
       "1   0.831858  0.531073  0.915118  \n",
       "2   0.849558  0.540845  0.919404  \n",
       "3   0.867257  0.549020  0.923485  \n",
       "4   0.893805  0.559557  0.926937  \n",
       "5   0.902655  0.566667  0.928806  \n",
       "6   0.867257  0.563218  0.929735  \n",
       "7   0.867257  0.576471  0.930702  \n",
       "8   0.858407  0.582583  0.931733  \n",
       "9   0.831858  0.594937  0.931647  \n",
       "10  0.814159  0.605263  0.931872  \n",
       "11  0.778761  0.602740  0.931786  \n",
       "12  0.752212  0.602837  0.931636  \n",
       "13  0.716814  0.593407  0.931969  \n",
       "14  0.716814  0.604478  0.931851  \n",
       "15  0.707965  0.603774  0.931421  \n",
       "16  0.681416  0.596899  0.933011  \n",
       "17  0.690265  0.611765  0.933043  \n",
       "18  0.681416  0.618474  0.933494  \n",
       "19  0.619469  0.583333  0.932914  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rf_depths(df_black)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63ed4bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'income'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'income'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m df_asian.head()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m m_gt = \u001b[43mdf_asian\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mincome\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str.contains(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m>\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*50\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*K?\u001b[39m\u001b[33m'\u001b[39m, case=\u001b[38;5;28;01mFalse\u001b[39;00m, na=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m m_le = df_asian[\u001b[33m'\u001b[39m\u001b[33mincome\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.contains(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<=\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*50\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*K?\u001b[39m\u001b[33m'\u001b[39m, case=\u001b[38;5;28;01mFalse\u001b[39;00m, na=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m df_asian[\u001b[33m'\u001b[39m\u001b[33mincome_binary\u001b[39m\u001b[33m'\u001b[39m] = np.select([m_gt, m_le], [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m], default=np.nan)  \u001b[38;5;66;03m# or default=0 if you prefer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kyle\\Documents\\Projects\\research-sem1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'income'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_asian.head()\n",
    "\n",
    "m_gt = df_asian['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "m_le = df_asian['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "df_asian['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_asian['income_binary'].head())\n",
    "print(df_asian['income_binary'].value_counts(dropna=False))\n",
    "df_asian.head()\n",
    "df_asian.drop(columns=['income'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42f13443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.703947</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.808449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.707237</td>\n",
       "      <td>0.907975</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.768831</td>\n",
       "      <td>0.475177</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.600897</td>\n",
       "      <td>0.812074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.680180</td>\n",
       "      <td>0.782383</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.817925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.680180</td>\n",
       "      <td>0.782383</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.823308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.740132</td>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.798982</td>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.632558</td>\n",
       "      <td>0.827428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.832921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.766447</td>\n",
       "      <td>0.908108</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.646766</td>\n",
       "      <td>0.835009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.836327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.766447</td>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.828087</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.635897</td>\n",
       "      <td>0.838140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.773026</td>\n",
       "      <td>0.896373</td>\n",
       "      <td>0.779279</td>\n",
       "      <td>0.833735</td>\n",
       "      <td>0.558559</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.642487</td>\n",
       "      <td>0.838909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.586538</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.838030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>0.806306</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.839129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.786184</td>\n",
       "      <td>0.882927</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.847775</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.839953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.840118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.842040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.792763</td>\n",
       "      <td>0.880383</td>\n",
       "      <td>0.828829</td>\n",
       "      <td>0.853828</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.840942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.856481</td>\n",
       "      <td>0.606383</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.843139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.844622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.792763</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.844842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.869159</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.843139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  accuracy  precision_0  recall_0      f1_0  precision_1  \\\n",
       "0           1  0.703947     0.902439  0.666667  0.766839     0.471429   \n",
       "1           2  0.707237     0.907975  0.666667  0.768831     0.475177   \n",
       "2           3  0.723684     0.920732  0.680180  0.782383     0.492857   \n",
       "3           4  0.723684     0.920732  0.680180  0.782383     0.492857   \n",
       "4           5  0.740132     0.918129  0.707207  0.798982     0.511278   \n",
       "5           6  0.750000     0.910112  0.729730  0.810000     0.523810   \n",
       "6           7  0.766447     0.908108  0.756757  0.825553     0.546218   \n",
       "7           8  0.763158     0.903226  0.756757  0.823529     0.542373   \n",
       "8           9  0.766447     0.895288  0.770270  0.828087     0.548673   \n",
       "9          10  0.773026     0.896373  0.779279  0.833735     0.558559   \n",
       "10         11  0.789474     0.895000  0.806306  0.848341     0.586538   \n",
       "11         12  0.782895     0.886139  0.806306  0.844340     0.578431   \n",
       "12         13  0.786184     0.882927  0.815315  0.847775     0.585859   \n",
       "13         14  0.789474     0.879808  0.824324  0.851163     0.593750   \n",
       "14         15  0.789474     0.879808  0.824324  0.851163     0.593750   \n",
       "15         16  0.792763     0.880383  0.828829  0.853828     0.600000   \n",
       "16         17  0.796053     0.880952  0.833333  0.856481     0.606383   \n",
       "17         18  0.796053     0.877358  0.837838  0.857143     0.608696   \n",
       "18         19  0.792763     0.873239  0.837838  0.855172     0.604396   \n",
       "19         20  0.789474     0.869159  0.837838  0.853211     0.600000   \n",
       "\n",
       "    recall_1      f1_1   roc_auc  \n",
       "0   0.804878  0.594595  0.808449  \n",
       "1   0.817073  0.600897  0.812074  \n",
       "2   0.841463  0.621622  0.817925  \n",
       "3   0.841463  0.621622  0.823308  \n",
       "4   0.829268  0.632558  0.827428  \n",
       "5   0.804878  0.634615  0.832921  \n",
       "6   0.792683  0.646766  0.835009  \n",
       "7   0.780488  0.640000  0.836327  \n",
       "8   0.756098  0.635897  0.838140  \n",
       "9   0.756098  0.642487  0.838909  \n",
       "10  0.743902  0.655914  0.838030  \n",
       "11  0.719512  0.641304  0.839129  \n",
       "12  0.707317  0.640884  0.839953  \n",
       "13  0.695122  0.640449  0.840118  \n",
       "14  0.695122  0.640449  0.842040  \n",
       "15  0.695122  0.644068  0.840942  \n",
       "16  0.695122  0.647727  0.843139  \n",
       "17  0.682927  0.643678  0.844622  \n",
       "18  0.670732  0.635838  0.844842  \n",
       "19  0.658537  0.627907  0.843139  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rf_depths(df_asian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_native.head()\n",
    "\n",
    "m_gt = df_native['income'].astype(str).str.contains(r'>\\s*50\\s*K?', case=False, na=False)\n",
    "m_le = df_native['income'].astype(str).str.contains(r'<=\\s*50\\s*K?', case=False, na=False)\n",
    "df_native['income_binary'] = np.select([m_gt, m_le], [1, 0], default=np.nan)  # or default=0 if you prefer\n",
    "print(df_native['income_binary'].head())\n",
    "print(df_native['income_binary'].value_counts(dropna=False))\n",
    "df_native.head()\n",
    "df_native.drop(columns=['income'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rf_depths(df_native)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
